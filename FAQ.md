# Project FAQ

## Will it be accurate?
From a technical standpoint, we would aim to have uploaded data geo-tagged.  
This involves using the user's phone locatation, which is usually accurate to meters.  
Combined with the high-quality audio, photo and video captured by modern smartphones,  
we would hope that gathered data would be suitably high-definition.  

### Bad actors
From an opeartional standpoint, it is a more complicated picture.  
Potential bad actors among our users include:  
- trolls
- bots
- police 

Bad actors can upload data which is invalid (false or misleading).  
This data may not be easily distinguishable from valid data.  
Given that we intend to make this data suitable for serious research,  
it is imperative that we have procedures to validate submitted data.  
From the initial release through to beta testing, we can reduce the impact of this  
by limiting the size and propagation of the user base (invitation-only access, ...).

Unfortunatly, verification of our user base for the purposes of validating data  
comes at the cost. As verification usually involves some form of user identification,  
such as a confirmation email sent to an address or a text to a mobile number,  
we need to treat verified user data as nuclear waste (see below).  
This means minimising it's collection and disposing of it carefully as-soon-as-possible.  
This has the added advantage of streamlining potential legal compliance (GDPR, ...).

A sensible option would be first releasing the app with minimal verification  
for a limited number of users, and adding verification if/when it becomes neccessary.

### Official validation
The gold standard in validating our data would involve cooperation with official bodies.  
Comparison between collected data and that collected by the police themselves  
would help us reliably detect and flag up invalid data.  
This would involve identification of actual police officers,  
so this may be a hard sell to the police themselves.  

With this being said, there is currently considerable public pressure on the police,  
thanks to the efforts of BLM, to make structural changes and face accountability.  
Given that misleading data could make the police look even worse than they actually are,  
it might be in the interests of the authorities to be less opaque.  



## Will it get people hurt?
The following scenarios have been considered, although of course this is not a complete list.

### Public-access data maliciously used by police/right-wingers/other-actors 
Police and extremists are considered together because:
- in countries like Germany, there is considerable crossover between these groups.  
- both groups pose the threat of violence towards users of the app.   

We can assume that the police themselves gather some data on their own activities.  
Therefore, it is likely that whatever public data we present may already be known to them,
and it would be of limited use to them.

We can also assume that the potential harm posed by the public data is minimised  
when this data is completely anonymous.  
Anonymisation requires:  
- avoiding at-all-costs unneccessary data collection, by which the user may be identifiable.
- avoiding so-far-as-possible verification (requiring email/telephone for confirmation),  
  and purging this data when it is no longer neccessary.
- allowing the user to find their public data without being identifiable,  
  such as using an arbitrary psuedo-random nickname instead of an email address..

Lastly we assume that any non-public data we collect will eventually be subject to breach  
then public scrutiny, fraud and identity theft.
This risk is also minimised by maximising user anonymitiy.

### Flawed app content leading to user injury and death
Clearly, provinding faulty information to the user during a police kontrolle could be fatal.  
As police are usually armed, the use case for the app involves a life-threatening sitation. 
We aim to minimise this risk by ensuring the legal information encoded in the app is of  
the highest accuracy, 

In Bavaria, we hope that Rotehilfe (legal aid organisation) come onboard with their expertise.
For the UK version, the minimum-viable-prototype mobile app (under development) uses GOV.uk  
(for example https://www.gov.uk/police-powers-to-stop-and-search-your-rights).  
This will be done properly before going live.
A Dutch version is also being considered.

### Flawed app UX leading to user injury and death
Encounters with the police are more dangerous for marginalised groups such as:
* People of Colour
* Sex workers
* Refugees
* Migrants
* Disabled people
* People with mental ilnesses
* Queer people
* Trans people
* ...

We can assume that a UX designer who is a straight white cis man is going to do a poor job  
creating a UX for these groups, because they are basing their design on different  
lived experiences. This is obviously a huge problem.  

We aim to minimise the risk of a harmful UX by doing this project explicitly anti-racist and inclusive way: in this case, by maximising the number of contributors from these groups,  
and minimising hierarchial relationships between them.

Having as many contributors (and eventually employees) from such groups serves two goals:  
- avoids replicating the institutional racism of the tech industry.
- delivering the best possible product we can.